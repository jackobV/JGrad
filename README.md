# JGrad

*J grad is a super simple back propagation and autogradient algorithm implementation engine.*

Jgrad's only purpose is to go back to basics and gain a deeper intuitive understanding behind the math of neural networks. 

### Sources

Right now most of the engine directly follows Andrej Karpathy's micrograd. 
(https://github.com/karpathy/micrograd)

I would like to experiment with some wild and interesting ideas that didn't make it to today's standard autograd engines (probably for a good reasons). But still sometimes its cool to see what couldve been.

